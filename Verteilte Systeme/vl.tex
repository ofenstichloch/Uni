\documentclass[a4paper]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{a4wide}
\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\geometry{a4paper,left=2cm,right=2cm, top=3cm, bottom=3cm}
\usepackage{listings}

\newcommand{\titel}[1]{\fancyhead[C]{#1}}
\newcommand{\name}{\fancyhead[L]{Alexander Landmesser}}
\newcommand{\matrikel}{\fancyhead[R]{}}
\newcommand{\pl}{\hspace*{1cm}}
\begin{document}
\title{Verteilte Systeme}
\maketitle
\section{ØMQ}
\subsection{Verwendung}
\begin{itemize}
\item[1. Context:] Es muss für ØMQ ein Kontext erstellt werden (das Umfeld)
\item[2. Socket:] Es muss ein Socket in diesem Kontext erstellt werden
\item[3. Sockettyp:] Was für eine Art Socket wird benötigt (SUB/PUB etc.)
\item[4. Binding:] Socket an eine Adresse und einen Port binden (Remote, oder Lokale für listening)
\item[5.1 Receive] Receive (blockierend), besonderer Messagetyp
\item[5.2 Send] Send, gegebener Messagetyp ist zu füllen

\end{itemize}
ØMQ Buffert alle Nachrichten bis zu einem gewissen Grad. So werden auch langsamere Reader oder später registrierte Subscriber bedient, jedoch ohne versicherung, dass sie alle Nachrichten empfangen.
\subsection{Patterns}
\begin{itemize}
\item[Request-Reply] Synchrone Request-Reply Kommunikation
\item[Push-Pull] Sender erwartet keine Rückantwort (Push), Empfänger benutzen Pull, um Nachricht zu empfangen.\\
Kann benutzt werden, um Lasten zu verteilen, weil eine Nachricht nur höchstens eimal empfangen werden kann.
\item[Pub/Sub] Ein Publisher sendet Nachrichten mit bestimmten Tags, alle Subscriber empfangen alle Nachrichten, die den vorgegebenen Tags des Subscribers entsprechen.
\end{itemize}
\subsection{Transportvarianten}
\begin{itemize}
\item[ipc:] Interprozess, FIFO etc.
\item[inproc:] Socketkommunikation innerhalb eines Prozesses.
\item[mMulticast:] ØMQ unterstützt Multicast, wenn das Netzwerk es unterstützt.
\end{itemize}
\subsection{PlayØMQ, Broker}
Sources generieren Zufallszahlen und geben sie an den Broker.\\
Worker nehmen Zahlen aus dem Broker und prüfen auf Primzahl.\\
Sinks hören auf Nummern/Primzahlen.
Broker: Sendet einkommende Zahlen per Push-Socket an Worker, sendet Zahlen und Primzahlen per PUB-Socket
Source: Request Reply auf Broker.\\
Worker: Push/Pull $\rightarrow$ Parallelisierung der Berechnung \\
Sink: Subscriber, die auf den Broker "Subscriben", mit dem entsprechenden Tag (number/primzahl)
\subsubsection{Nachrichten}
Senden und Empfangen von Daten muss besonders behandelt werden, da Nachrichten erstellt werden müssen.\\
Nachrichten bestehen aus Tag (identifier Char) und Wert (long)
\subsubsection{Source}
Benötigt URL von Broker\\
Erstelle REQ (Request) Socket, der mit dem Broker verbindet.\\
Source generiert Zahlen, sendet sie an Broker und wartet, bis dieser den Empfang bestätigt hat.
\subsubsection{Broker}
Broker hat Sockets für REP (Reply) für Source, PUB (Publisher) für Sinks, PUSH für Worker.\\
Im Beispiel ist Endpoint eine Methode, die die Befehle zum Erstellen eines einfachen Sockets zusammenfasst.\\
Broker empfängt Zahl von Source, bestätigt dem Empfang, publiziert die Nummer, sendet sie an die Worker, wartet auf die Antwort und publiziert u.U. die Primzahl.
\subsubsection{Worker}
Verbindet per PULL und REQ (Request) Socket auf den Broker. \\
Empfängt vom Broker per PULL Zahlen, prüft diese und sendet sie u.U. per REQ an Broker. Wenn die Primzahl gesendet wird, muss der Worker wieder auf die Antwort (REPly) des Broker warten.
\subsubsection{Sink}
Erstellt SUB (Subscriber) Socket, über den er vom Broker Daten empfängt. \\
Beim Erstellen wird festgelegt, auf welche Tags der Subscriber hört.\\
\section{Verteilung von Last}

Kreative Lastverteilung: Verteilte Programmierung.\\
Mechanische Lastverteilung: Verteilung auf Rechner, gleiche Auslastung der verwendeten Rechner\\

Durch verteilte Rechner ist die "aktuelle Last" verzögert, um die Latenz zwischen A und B. A schickt also Last an B, auch wenn B inzwischen eine hohe Last erreicht hat.\\
Lösung: A kann anhand der verteilten Last merken, wie viel Last ungefähr an B vergeben wurde (wenn B Last nicht weitergibt).\\

Paketweitergabe:\\
\begin{itemize}
\item Wenn der Code lokal vorhanden ist, muss er kopiert werden (achte auf identische Pfadnamen etc.)\\
	Bei Netzwerklaufwerken geht Zeit verloren, da das Netzwerklaufwerk limitierende Bandbreite hat.
\item Verteiler schickt Programmcode mit (Große Datenmenge, Achtung Viren)

\end{itemize}

\subsection{Architektur}
Erstellen einer Lastmetrik: Welche Last hat ein Rechner, welche Last erzeugt ein Paket?\\
Verteilung der Last der beteiligten Rechner: Entscheidungsgundlage für Verteiler.\\
Verteilung des Lastpaketes auf gewählte Rechner: Welche Informationen müssen übertragen werden.\\
\subsection*{Lastmetriken}
\begin{itemize}
\item Prozessorauslastung (Anzahl Prozesse, CPU-Zeit)
\item Speicherauslastung (Bedarf etc.)
\item Kommunikationslast (IO, Netzwerk)
\end{itemize}
\subsubsection*{Pull}
Zieht Lastwerten an. (Unterforderte Rechner suchen Last)\\
Lastwert wird bei der Erzeugung eines Paketes ermittelt.\\
Varianten:
\begin{itemize}
\item[Von allen Rechnern:] Verteiler sendet Broadcast und fragt nach Last, alle Rechner antworten mit eignener Last.\\
	Verbesserung: Antowrt wird verzögert, je nach eigener Last. Damit antwortet der am wenigsten ausgelastete als erstes.
\item[Feste Teilmenge:] Erreriche bestimmte Worker
\item[Zufällige Teilmenge:]Frage zufällige Worker an
\end{itemize}
\subsubsection*{Push}
Lastwerte verteilen.  (Überforderte Rechner verteilen Last)\\

\subsection{Verteilungsverfahren}
Last sollte so verteilt werden, dass Rechen- und Speicherlast gleich verteilt ist und die Kommunikation möglichst lokal stattfindet.
\begin{itemize}
\item[Statisches Verfahren] Optimale Verteilung vor dem Start der Anwendung ermitteln.\\ 
Alle Bestandteile der Lastmetrik sind für alle Prozesse bekannt.\\
Findet häufig Anwendung, Last ist vorher meistens bekannt (Meterologie etc.)
\item[Dynamisches Verfahren] Ausführungsort wird für jeden Prozess ermittelt. 
	\begin{itemize}
	\item[Mit Migration] Migration heißt, die Adressräume und die Prozessstati zu übertragen. Es muss gewartet werden, bis alle Threads keine OS-Ressourcen mehr benutzen.\\
	Problem: Adressräume sind u.U. sehr groß. \\
	Lösung: Copy-on-Reference: Kopiere Adressen, wenn sie benötigt werden. (Reduziert Speicherlast auf Quellknoten nicht).
	\item[Ohne Migration] Hoher Aufwand die Lastverteilung zu bestimmen.
	\end{itemize}
\end{itemize}
Durchgesetzt hat sich \underline{Initial Placement}\\
Bei Paketentstehung Zielknoten bestimmen, im Extremfall zufällige Wahl.\\
Ist durchaus das schnellste Verfahren.\\
\subsection{Zeit bei Verteilung}
2 Möglichkeiten:
\begin{itemize}
\item 1. Synchronisieren der Uhren der Systeme
\item 2. Erstellung eines neuen Zeitmaßes
\end{itemize}
\subsubsection{Synchronisation der Uhren}
Es wird angenommen, dass jede Uhr ungenau ist und eine lineare Abweichung besitzen.\\
Ziel: Zeit innerhlab eines Rahmen halten und Abweichungen durch Synchronisation verhindern.\\
Ein System hat eine genaue Zeit, die an andere Systeme verteilt wird:\\
Die nachgestellten Uhren hinken immer ein wenig hinterher. \\
DCF77 erste Zeitsender in Offenbach, senden Zeitsignal über Langwelle. Pulst jede Sekunde, Zusatzdaten auf das Sekundensignal moduliert.\\
\textbf{Vergleich nach F. Christian}:\\
Client muss herausfinden, was die Laufzeit des Singals ist. Er speichert seine Zeit, wenn das Signal losgeschickt wird und wenn die Antwort empfangen wird. Der Client berechnet die Mitte aus Empfangszeit-Sendezeit, dieser Zeitpunkt wird auf die Zeit des Signals (Servers) gesetzt.\\
Lokale Uhr kann schneller/langsamer sein. Zurückstellen der Zeit ist unangenehm, deswegen werden Anti-Schaltmillisekunden eingeführt, die die Uhr bei Bedarf leicht abbremsen. Auch beim Vorstellen der Uhr werden meist Schaltmillisekunden verwendet.\\
\textbf{NTP}:\\
Server werden in Genauigkeitsstufen unterteilt, Stratum1 ist genau. Stratum 3 oder mehr ist inzwischen selten.\\
Lokale NTP Server ermöglichen eine sehr genaue lokale Zeit im Netzwerk. Die Uhr ist nicht unbedingt genau die Globalzeit, alle lokalen Systeme laufen aber synchron.\\
\subsubsection{Lamportzeit}
Bei jedem lokalen Ereignis "tickt" die logische Uhr. Lokale Ereignisse können Instruktionen oder spezielle Ereignisse sein. Wenn ein Ereignis eintritt, wird diesem ein Zeitstempel zugewiesen. Ein späteres Ereignis tritt auch wirklich später ein und KANN kausal Abhängig von denn vorherigen Ereignissen des selben Systems sein. Kausale Abhängigkeiten zwischen verschiedenen Systemen kann nur durch Datenaustausch ausgelöst werden. Wenn zwei Ereignisse kausal abhängig sind, muss das abhängige Ereignis einen neueren Zeitstempel besitzen als die Ursache.\\
\underline{Lamportzeit}:\\
Die logische Uhr tickt bei jedem Ereignis hoch. Der Sender schickt seinen Zeitstempel beim Senden mit. Der Empfänger stellt seine Uhr auf den größeren der beiden Zeitstempel (sein eigener und der vom Sender). \\
Man kann von der Kausalität auf die Zeitstempel schließen, z.B. zum korrigieren. Die Zeitstempel liefern jedoch keine Informationen über die Kausalität, frühere Ereignisse müssen nicht abhängig sein.\\
Problem: Zähler erreicht Maximum des Speichers und läuft über. Praktisch selten erreichbar, 64Bit Zeitstempel reicht LANGE.\\
\subsubsection{Vektorzeit}
Bei n Rechnern, ein Vektor der Dimension n.\\
Bei lokalen Ereignissen erhöht das System den eigenen Wert im Vektor, die anderen bleiben gleich. Beim Senden, wird der lokale Eintrag erhöht und der gesamte Vektor mitgeschickt. Beim Empfangen wird komponentenweise das Maximum in den eigenen Vektor übernommen, vorher wird auch der eigenen Wert um eins erhöht, da das Empfangsereignis ein lokales Ereignis ist.\\
Wenn ein Vektor komplett komponentenweise größer gleich ist als ein anderer, so ist das Ereignis kausal abhängig. Dabei MUSS mindestens eine Komponente echt größer sein. In allen anderen Fällen sind die Ereignisse unabhängig.\\
\subsection{Verteilter Wechselseitiger Ausschluss}
Mehrere Prozesse dürfen eine Aufgabe nur einmal gleichzeitig ausführen.\\
Semaphoren etc. gehen nicht, da diese einen gemeinsamen Speicher benötigen.\\
\subsubsection{Zentraler Ansatz}
Eine Zentrale verwaltet die Ausführungen. Clients senden Requests, Server erlaubt bestimmte Requests.
Damit sortiert/erlaubt der Server bestimmte Requests nur, wenn kein anderer Client diesen gerade bearbeitet.
Client benachrichtigt den Server, wenn er einen kritischen Abschnitt verlässt.\\
Das System hat eine geringe Nachrichtenkomplexität, es werden nur 3 Nachrichten benötigt pro kritischem Abschnitt.\\
Server ist Single point of failure, wenn dieser ausfällt, fällt das System aus.\\
Das System ist assymetrisch, der Server führt anderen Code aus, als die Clients.
\subsubsection{Token-Ring}
Ringanordnung, Prozesse (Clients) schicken sich Token zu. Nur der Prozess mit Token, darf den kritischen Abschnitt betreten.\\
Ein Client, der nicht in einen kritischen Zustand will, gibt das Token weiter. Wenn ein Prozess einen kritischen Abschnitt verlässt gibt dieser das Token weiter.
\subsubsection{Lamport}
Zentraler Server hat eine Prozess-Warteschlange, Client Requests werden eingereiht, bei einem Release wird dem ersten in der Schlange ein Grant geschickt. Jeder Client verwaltet eine solche Liste und dient somit als "Server". Diese Listen werden identisch gehalten.\\
Client schickt Request an alle beteiligten Prozesse, alle reihen es in ihre Liste ein. Dem Request wird ein Zeitstempel (erweiterte Lamport Zeit) mitgeschickt. Alle anderen Clients bestätigen diesen Request. Erst wenn alle Clients bestätigt haben, darf der kritische Abschnitt betreten werden.\\
Ist die Liste leer, muss trotzdem auf alle Bestätigungen gewartet werden.\\
Das erste Element der Liste kann erst dann ausgeführt werden, wenn es sicher keinen Request mehr gibt oder auch kein Request mehr kommen wird, der vor diesem Element eingereiht würde (Achtung! Lamportzeit != Realzeit).\\
Anmerkung: Die Kommunikation zwischen zwei Clients ist so gebaut, dass beim Empfang eines Paketes klar definiert ist, dass nun kein weiteres Paket mit einem kleineren Zeitstempel kommen kann (von diesem Client).\\
Ein Client $P_i$ ermittelt das Minimum aller Zeitstempel der Bestätigungen. Damit kann $P_i$ die Liste in zwei Teile teilen. Alle Einträge mit kleinerem Zeitstempel können sicher ausgeführt werden, alle mit größer oder gleichem sind noch abhängig. Das wird dadurch gewährleistet, dass festgelegt ist, dass die Zeitstempel streng wachsend sind.\\
\includegraphics[scale=0.5]{lamport1.png}
\subsubsection{Matrix (Maekawa)}
Prozesse werden in einer Matrix angeordnet. Ein Knoten, der in einen kritischen Abschnitt eintreten will, sendet seinen Request an alle Knoten in seiner Zeile und seiner Spalte. Der Rest enspricht dem Lamport-Ansatz.
\end{document}
